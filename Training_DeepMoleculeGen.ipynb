{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import sys\n",
    "import models, data\n",
    "from data import get_mol_spec\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='datasets/input_Norm.txt'\n",
    "ckpt_dir='ckpt'\n",
    "ctx = mx.cpu()\n",
    "cond = data.Delimited()\n",
    "N_C = 7\n",
    "batch_size=5\n",
    "batch_size_test=15\n",
    "num_workers=0\n",
    "num_folds = 5\n",
    "fold_id = 0\n",
    "k=3\n",
    "p=0.8\n",
    "F_e=16\n",
    "F_h=(32, 64, 128, 128, 256, 256)\n",
    "F_skip=256\n",
    "F_c=(512, )\n",
    "Fh_policy=128\n",
    "activation='relu'\n",
    "N_rnn=3\n",
    "lr=1e-3\n",
    "wd = 0.0005\n",
    "clip_grad=3.0\n",
    "iterations=1000\n",
    "summary_step=10\n",
    "\n",
    "with open(file_name) as f:\n",
    "    dataset = data.Lambda(f.readlines(), lambda _x:_x.strip('\\n').strip('\\r'))\n",
    "if all([os.path.isfile(os.path.join(ckpt_dir, _n)) for _n in ['log.out', 'ckpt.params', 'trainer.status']]):\n",
    "    is_continuous = True\n",
    "    print(\"continue\")\n",
    "else:\n",
    "    is_continuous = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_train = data.KFold(dataset, k=num_folds, fold_id=fold_id, is_train=True)\n",
    "db_test = data.KFold(dataset, k=num_folds, fold_id=fold_id, is_train=False)\n",
    "sampler_train = data.BalancedSampler(cost=[len(l.split('\\t')[0]) for l in db_train], batch_size=batch_size)\n",
    "loader_train = data.CMolRNNLoader(db_train, batch_sampler=sampler_train, num_workers=num_workers,k=k, p=p, conditional=cond,prefetch=2)\n",
    "sampler_test = data.BalancedSampler(cost=[len(l.split('\\t'[0])) for l in db_test], batch_size=batch_size_test)\n",
    "loader_test = data.CMolRNNLoader(db_test, batch_sampler=sampler_test, num_workers=num_workers,k=k, p=p, conditional=cond,prefetch=2)\n",
    "\n",
    "it_train, it_test = iter(loader_train), iter(loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_continuous:\n",
    "    configs = {'N_C': N_C,\n",
    "                'F_e': F_e,\n",
    "                'F_h': F_h,\n",
    "                'F_skip': F_skip,\n",
    "                'F_c': F_c,\n",
    "                'Fh_policy': Fh_policy,\n",
    "                'activation': activation,\n",
    "                'rename': True,\n",
    "                'N_rnn': N_rnn}\n",
    "    with open(os.path.join(ckpt_dir, 'configs.json'), 'w') as f:\n",
    "        json.dump(configs, f)\n",
    "else:\n",
    "    with open(os.path.join(ckpt_dir, 'configs.json')) as f:\n",
    "        configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.CVanillaMolGen_RNN(get_mol_spec().num_atom_types, get_mol_spec().num_bond_types, D=2, **configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_continuous:\n",
    "    model.collect_params().initialize(mx.init.Xavier(magnitude=1), force_reinit=True,ctx=ctx)\n",
    "if is_continuous:\n",
    "    print(\"continue\")\n",
    "    model.collect_params().initialize(mx.init.Xavier(magnitude=1), force_reinit=True,ctx=ctx)\n",
    "    model.load_parameters(os.path.join(ckpt_dir, 'ckpt.params'),ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = mx.optimizer.Adam(learning_rate=lr, wd=wd)\n",
    "trainer = gluon.Trainer(model.collect_params(), opt)\n",
    "if is_continuous:\n",
    "    trainer.load_states(os.path.join(ckpt_dir, 'trainer.status'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_continuous:\n",
    "    t0 = time.time()\n",
    "    global_counter = 0\n",
    "    epochs = 0\n",
    "else:\n",
    "    with open(os.path.join(ckpt_dir, 'log.out')) as f:\n",
    "        records = f.readlines()\n",
    "        if records[-1] != 'Training finished\\n':\n",
    "            final_record = records[-1]\n",
    "            print(final_record)\n",
    "        else:\n",
    "            final_record = records[-2]\n",
    "            print(final_record)\n",
    "    count, epochs, t_final = int(final_record.split('\\t')[0]), float(final_record.split('\\t')[1]) ,float(final_record.split('\\t')[2])\n",
    "    t0 = time.time() - t_final\n",
    "    global_counter = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_num = len(loader_train)\n",
    "epoch_size = 200\n",
    "decay=0.015\n",
    "decay_step= 10000\n",
    "compare_val_loss = 10000\n",
    "model_path = ckpt_dir + '{epoch:02d}-{val_loss:4f}.ckpt'\n",
    "mx.random.seed(129)\n",
    "with open(os.path.join(ckpt_dir, 'log.out'),mode='w' if not is_continuous else 'a') as f:\n",
    "    if not is_continuous:\n",
    "        f.write('step\\tepochs\\ttime(s)\\tloss\\tlr\\tval_loss\\n')\n",
    "    losses = []    \n",
    "    while True:\n",
    "        t1 = time.time()\n",
    "        global_counter += 1\n",
    "        try:\n",
    "            inputs = next(it_train)\n",
    "        except StopIteration:\n",
    "            it_train = iter(loader_train)\n",
    "            inputs = next(it_train)\n",
    "        inputs = data.CMolRNNLoader.from_numpy_to_tensor(inputs,ctx=ctx)\n",
    "        with autograd.record():\n",
    "            loss = model(*inputs)\n",
    "            loss = sum(loss)\n",
    "            loss.backward()\n",
    "        nd.waitall()\n",
    "        gc.collect()\n",
    "        losses.append(loss)\n",
    "        trainer.step(1, ignore_stale_grad=True)\n",
    "        if global_counter % 100 == 0:\n",
    "            print(str(global_counter)+\"  \"+str(loss))\n",
    "        if global_counter % decay_step == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * (1.0 - decay))\n",
    "        if global_counter % batch_num == 0:\n",
    "            epochs += 1\n",
    "            mean_loss = np.mean([l.asscalar() for l in losses])\n",
    "            print(\"mean_loss\",mean_loss)\n",
    "            val_losses = []\n",
    "            ctx.empty_cache ()\n",
    "            for i in range(len(loader_test)):\n",
    "                try:\n",
    "                    val_inputs = next(it_test)\n",
    "                except StopIteration:\n",
    "                    it_test = iter(loader_test)\n",
    "                    val_inputs = next(it_test)\n",
    "                val_inputs = data.CMolRNNLoader.from_numpy_to_tensor(val_inputs,ctx=ctx)\n",
    "                val_loss =  model(*val_inputs)\n",
    "                val_loss = sum(val_loss)\n",
    "                nd.waitall()\n",
    "                gc.collect()\n",
    "                val_losses.append(val_loss)\n",
    "            mean_val_loss = np.mean([l.asscalar() for l in val_losses])\n",
    "            ctx.empty_cache ()\n",
    "            #print(\"val_fin\")\n",
    "            model.save_parameters(os.path.join(ckpt_dir, 'ckpt.params'))\n",
    "            #print(\"save\")\n",
    "            trainer.save_states(os.path.join(ckpt_dir, 'trainer.status'))\n",
    "            #print(\"state_save\")\n",
    "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(global_counter,epochs,float(time.time() - t0), mean_loss, trainer.learning_rate, mean_val_loss))\n",
    "            f.flush()\n",
    "            print(\"< epochs = \",int(epochs), \"| loss = \", mean_loss, \"| time = \" ,time.time()-t0)#, \"| val_loss\", mean_val_loss ,\" >\")\n",
    "            if mean_val_loss < compare_val_loss:\n",
    "                model.save_parameters(model_path.format(epoch=int(epochs), val_loss=mean_val_loss))\n",
    "                compare_val_loss = mean_val_loss\n",
    "            if int(epochs) == epoch_size:\n",
    "                break\n",
    "    model.save_parameters(os.path.join(ckpt_dir, 'ckpt.params'))\n",
    "    trainer.save_states(os.path.join(ckpt_dir, 'trainer.status'))\n",
    "    f.write('Training finished\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxnet_tf2",
   "language": "python",
   "name": "mxnet_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
